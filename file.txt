#dfs bfs

graph = {
    '1': ['2', '14'],
    '2': [],
    '14': ['12', '5'],
    '12': [],
    '5': ['4'],
    '4': []
}

visited = []
a = []
def bfs(graph, visited, node):
    visited.append(node)
    a.append(node)

    while a:
        e = a.pop(0)
        print(e,end=" ")

        for i in graph[e]:
            if i not in visited:
                visited.append(i)
                a.append(i)


bfs(graph, visited, '1')

"""
graph = {
    '1':['2','3'],
    '2':['4'],
    '4':['5'],
    '5':[],
    '3':['6','7'],
    '6':[],
    '7':[]
}

visited = []

def dfs(visited, graph, node):
    if node not in visited:
        print (node)
        visited.append(node)
        for i in graph[node]:
            dfs(visited, graph, i)


dfs(visited, graph, '1')
"""

#mp xor
def NOT(x):
    return 1 if x == 0 else 0

def AND(x1, x2):
    return 1 if x1 == 1 and x2 == 1 else 0

def OR(x1, x2):
    return 1 if x1 == 1 or x2 == 1 else 0

def XOR(x1, x2):
    # function1: z1 = x1 AND NOT x2
    z1 = AND(x1, NOT(x2))
    # function2: z2 = NOT x1 AND x2
    z2 = AND(NOT(x1), x2)
    # function3: y = z1 OR z2
    y = OR(z1, z2)
    return y

# Test XOR
print("XOR Truth Table")
for x1 in [0, 1]:
    for x2 in [0, 1]:
        print(f"{x1} XOR {x2} = {XOR(x1, x2)}")

#perceptron
import matplotlib.pyplot as plt

# Input patterns
x1 = [1, 1, -1, -1]
x2 = [1, -1, 1, -1]
t = [1, 1, 1, -1]

# Initial weights and bias
w1, w2, b = 0, 1, 0
a = 1
o = 0.2

# Training loop
for i in range(len(x1)):
    y = (x1[i] * w1) + (x2[i] * w2) + b
    print("Value of y is", y)

    if y > o:
        Y = 1
    elif -o <= y <= o:
        Y = 0
    else:
        Y = -1

    print(f"The value of Y is {Y}")

    if t[i] != Y:
        w1 = w1 + (a * t[i] * x1[i])
        w2 = w2 + (a * t[i] * x2[i])
        b = b + (a * t[i])

    print(f"Updated weights: w1 = {w1}, w2 = {w2}, bias = {b}")

# Plotting points
for i in range(len(x1)):
    if t[i] == 1:
        plt.scatter(x1[i], x2[i], color='blue', marker='o')
    else:
        plt.scatter(x1[i], x2[i], color='red', marker='x')

# Decision boundary line: w1*x + w2*y + b = 0
# y = -(w1/w2)*x - (b/w2)
import numpy as np
x_vals = np.linspace(-2, 2, 100)
y_vals = -(w1/w2)*x_vals - (b/w2)
plt.plot(x_vals, y_vals, color='green', label='Decision Boundary')


plt.xlabel('x1')
plt.ylabel('x2')
plt.title('Perceptron Learning Plot')
plt.legend()
plt.grid(True)
plt.show()


#delta
def delta(a,w,x,t,d):
    error = d - y
    fnet = 0.5 * (1 - y**2)
    d = error * fnet * w * a
    wnew = w + d

    print(f"error = {error}")
    print(f"fnet = {fnet}")
    print(f"delta = {d}")

    return wnew

a=0.3
w=0.4
x=0.5
y=0.5
d=0.7

for i in range(5):
    w = delta(a,w,x,y,d)
    print("updated weight = ", w)


#a*
import heapq

def a_star(graph, h, start, goal):
    open_list = [(0, start)]
    g = {node: float('inf') for node in graph}
    g[start] = 0
    came_from = {}

    while open_list:
        _, current = heapq.heappop(open_list)
        if current == goal:
            path = []
            while current in came_from:
                path.append(current)
                current = came_from[current]
            path.append(start)
            return path[::-1], g[goal]

        for neighbor, cost in graph[current].items():
            new_g = g[current] + cost
            if new_g < g[neighbor]:
                g[neighbor] = new_g
                heapq.heappush(open_list, (new_g + h[neighbor], neighbor))
                came_from[neighbor] = current

    return None, float('inf')

# Example
graph = {
    'A': {'B': 1, 'C': 2},
    'B': {'D': 4, 'C': 3},
    'C': {'D': 1},
    'D': {}
}

h = {'A': 1, 'B': 0, 'C': 2, 'D': 2}

path, cost = a_star(graph, h, 'A', 'D')
print("Path:", path)
print("Cost:", cost)


#is prime
% Base case: 0 and 1 are not prime.
is_prime(0) :- false.
is_prime(1) :- false.

% Check if N is prime by ensuring it has no divisors other than 1 and itself.
is_prime(N) :-
    N > 1,
    \+ has_factor(N, 2).

% Helper predicate to check if N has any factors from 2 to sqrt(N).
has_factor(N, F) :-
    F * F =< N,     % Stop if F exceeds sqrt(N)
    N mod F =:= 0.  % True if F divides N evenly
has_factor(N, F) :-
    F * F =< N,
    F1 is F + 1,
    has_factor(N, F1).

% Example query:
% ?- is_prime(17).
% Output: true.


#factorial
factorial(0,1).
factorial(X,result):-
    X > 0,
    X1= X - 1,
    factorial(X1,demo)
    result is X * demo

#max in list
% Base case: If there's only one element, it's the largest.
max_list([X], X).

% Recursive case: Compare the head with the maximum of the tail.
max_list([H|T], Max) :-
    max_list(T, TailMax),    % Find the largest in the tail
    Max is max(H, TailMax).  % Compare head with tail max

#min from list
% Base case: If there's only one element, it is the smallest.
min_list([X], X).

% Recursive case: Compare the head with the minimum of the tail.
min_list([H|T], Min) :-
    min_list(T, TailMin),  % Find the smallest in the tail
    Min is min(H, TailMin).  % Compare head with tail min
